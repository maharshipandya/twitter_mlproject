{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, os \n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.read_csv(\"/Users/maharshi/Desktop/Fall 2019/STOR 565/project/Tweets/tweets-20191106-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encod = LabelEncoder()\n",
    "finaldf['partyNum'] = encod.fit_transform(finaldf['party'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>CleanText</th>\n",
       "      <th>party</th>\n",
       "      <th>partyNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1190407200109318144</td>\n",
       "      <td>whistleblower must come forward explain accoun...</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1190400372180807680</td>\n",
       "      <td>impeach someone done anything wrong</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190385966621569024</td>\n",
       "      <td>oh beto dropped race president despite saying ...</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1190383074632257536</td>\n",
       "      <td>republicans never unified right dems mess corr...</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1190375834529468416</td>\n",
       "      <td>president federal government wants wonerful ci...</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TweetId                                          CleanText  \\\n",
       "0  1190407200109318144  whistleblower must come forward explain accoun...   \n",
       "1  1190400372180807680                impeach someone done anything wrong   \n",
       "2  1190385966621569024  oh beto dropped race president despite saying ...   \n",
       "3  1190383074632257536  republicans never unified right dems mess corr...   \n",
       "4  1190375834529468416  president federal government wants wonerful ci...   \n",
       "\n",
       "        party  partyNum  \n",
       "0  republican         1  \n",
       "1  republican         1  \n",
       "2  republican         1  \n",
       "3  republican         1  \n",
       "4  republican         1  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(finaldf,list(finaldf['partyNum'].values),test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267, 4) (317, 4)\n",
      "1584\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)\n",
    "print(len(finaldf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Pre-trained Glove Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267, 50)\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 30000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size,lower=False,split=' ')\n",
    "tokenizer.fit_on_texts((X_train['CleanText'].values))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences((X_train['CleanText'].values))\n",
    "data = pad_sequences(sequences,maxlen=50)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((X_train['CleanText'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('/Users/maharshi/Desktop/Fall 2019/STOR 565/project/glove.twitter.27B/glove.twitter.27B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Sequential()\n",
    "mod.add(Embedding(vocabulary_size, 100, input_length=50, weights=[embedding_matrix], trainable=False))\n",
    "mod.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "mod.add(Dense(1, activation='sigmoid'))\n",
    "mod.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 760 samples, validate on 507 samples\n",
      "Epoch 1/20\n",
      "760/760 [==============================] - 3s 4ms/step - loss: 0.6135 - accuracy: 0.6803 - val_loss: 0.5118 - val_accuracy: 0.7890\n",
      "Epoch 2/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.4483 - accuracy: 0.8026 - val_loss: 0.4459 - val_accuracy: 0.8028\n",
      "Epoch 3/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.3985 - accuracy: 0.8276 - val_loss: 0.4231 - val_accuracy: 0.8343\n",
      "Epoch 4/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.3704 - accuracy: 0.8276 - val_loss: 0.4029 - val_accuracy: 0.8363\n",
      "Epoch 5/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.3186 - accuracy: 0.8684 - val_loss: 0.4342 - val_accuracy: 0.8284\n",
      "Epoch 6/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.3313 - accuracy: 0.8553 - val_loss: 0.3837 - val_accuracy: 0.8402\n",
      "Epoch 7/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.3043 - accuracy: 0.8724 - val_loss: 0.3707 - val_accuracy: 0.8402\n",
      "Epoch 8/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2876 - accuracy: 0.8763 - val_loss: 0.3772 - val_accuracy: 0.8501\n",
      "Epoch 9/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2448 - accuracy: 0.9026 - val_loss: 0.3854 - val_accuracy: 0.8402\n",
      "Epoch 10/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2660 - accuracy: 0.8855 - val_loss: 0.4314 - val_accuracy: 0.8343\n",
      "Epoch 11/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2482 - accuracy: 0.8974 - val_loss: 0.3616 - val_accuracy: 0.8501\n",
      "Epoch 12/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2194 - accuracy: 0.8961 - val_loss: 0.3472 - val_accuracy: 0.8619\n",
      "Epoch 13/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2121 - accuracy: 0.9132 - val_loss: 0.3886 - val_accuracy: 0.8481\n",
      "Epoch 14/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1947 - accuracy: 0.9211 - val_loss: 0.3842 - val_accuracy: 0.8442\n",
      "Epoch 15/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1832 - accuracy: 0.9250 - val_loss: 0.3688 - val_accuracy: 0.8659\n",
      "Epoch 16/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1737 - accuracy: 0.9303 - val_loss: 0.3841 - val_accuracy: 0.8580\n",
      "Epoch 17/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1670 - accuracy: 0.9316 - val_loss: 0.3776 - val_accuracy: 0.8422\n",
      "Epoch 18/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1755 - accuracy: 0.9289 - val_loss: 0.3392 - val_accuracy: 0.8718\n",
      "Epoch 19/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1551 - accuracy: 0.9474 - val_loss: 0.3581 - val_accuracy: 0.8619\n",
      "Epoch 20/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1336 - accuracy: 0.9553 - val_loss: 0.3664 - val_accuracy: 0.8540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a37a11fd0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(data, np.array(y_train), validation_split=0.4, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.metrics.MeanMetricWrapper at 0x1a65301d30>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6589487 ],\n",
       "       [0.23531099]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_complaint = ['stock market up big enjoy','equal']\n",
    "seq1 = tokenizer.texts_to_sequences(new_complaint)\n",
    "da1 = pad_sequences(seq1, maxlen=50)\n",
    "pred1 = mod.predict(da1)\n",
    "#labels=['Republican','Democrat']\n",
    "#print(pred1, labels[np.argmax(pred1)])\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5986774]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-64413619f1b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprojector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mTENSORBOARD_FILES_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/maharshi/Desktop/Fall 2019/STOR 565/project/TensorBoard\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "TENSORBOARD_FILES_PATH = \"/Users/maharshi/Desktop/Fall 2019/STOR 565/project/TensorBoard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           10000000  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,080,501\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 10,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "       2195,  428,   29,   30,  387,  120,  292,  121,  122,  655, 1481,\n",
       "        556,   93, 2196,  187,  656,   57, 1126,   50,  100,  429,    2,\n",
       "        247, 2197,  268,  317,   19,   34], dtype=int32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2195,\n",
       " 428,\n",
       " 29,\n",
       " 30,\n",
       " 387,\n",
       " 120,\n",
       " 292,\n",
       " 121,\n",
       " 122,\n",
       " 655,\n",
       " 1481,\n",
       " 556,\n",
       " 93,\n",
       " 2196,\n",
       " 187,\n",
       " 656,\n",
       " 57,\n",
       " 1126,\n",
       " 50,\n",
       " 100,\n",
       " 429,\n",
       " 2,\n",
       " 247,\n",
       " 2197,\n",
       " 268,\n",
       " 317,\n",
       " 19,\n",
       " 34]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
