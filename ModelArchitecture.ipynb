{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, os \n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.read_csv(\"/Users/maharshi/Desktop/Fall 2019/STOR 565/project/Tweets/tweets-20191106-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encod = LabelEncoder()\n",
    "finaldf['partyNum'] = encod.fit_transform(finaldf['party'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>CleanText</th>\n",
       "      <th>party</th>\n",
       "      <th>partyNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1190407200109318144</td>\n",
       "      <td>whistleblower must come forward explain accoun...</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1190400372180807680</td>\n",
       "      <td>impeach someone done anything wrong</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190385966621569024</td>\n",
       "      <td>oh beto dropped race president despite saying ...</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1190383074632257536</td>\n",
       "      <td>republicans never unified right dems mess corr...</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1190375834529468416</td>\n",
       "      <td>president federal government wants wonerful ci...</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TweetId                                          CleanText  \\\n",
       "0  1190407200109318144  whistleblower must come forward explain accoun...   \n",
       "1  1190400372180807680                impeach someone done anything wrong   \n",
       "2  1190385966621569024  oh beto dropped race president despite saying ...   \n",
       "3  1190383074632257536  republicans never unified right dems mess corr...   \n",
       "4  1190375834529468416  president federal government wants wonerful ci...   \n",
       "\n",
       "        party  partyNum  \n",
       "0  republican         1  \n",
       "1  republican         1  \n",
       "2  republican         1  \n",
       "3  republican         1  \n",
       "4  republican         1  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(finaldf,list(finaldf['partyNum'].values),test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267, 4) (317, 4)\n",
      "1584\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)\n",
    "print(len(finaldf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Pre-trained Glove Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267, 50)\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 30000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size,lower=False,split=' ')\n",
    "tokenizer.fit_on_texts((X_train['CleanText'].values))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences((X_train['CleanText'].values))\n",
    "data = pad_sequences(sequences,maxlen=50)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((X_train['CleanText'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('/Users/maharshi/Desktop/Fall 2019/STOR 565/project/glove.twitter.27B/glove.twitter.27B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Sequential()\n",
    "mod.add(Embedding(vocabulary_size, 100, input_length=50, weights=[embedding_matrix], trainable=False))\n",
    "mod.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "mod.add(Dense(1, activation='sigmoid'))\n",
    "mod.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 760 samples, validate on 507 samples\n",
      "Epoch 1/20\n",
      "760/760 [==============================] - 3s 4ms/step - loss: 0.6135 - accuracy: 0.6803 - val_loss: 0.5118 - val_accuracy: 0.7890\n",
      "Epoch 2/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.4483 - accuracy: 0.8026 - val_loss: 0.4459 - val_accuracy: 0.8028\n",
      "Epoch 3/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.3985 - accuracy: 0.8276 - val_loss: 0.4231 - val_accuracy: 0.8343\n",
      "Epoch 4/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.3704 - accuracy: 0.8276 - val_loss: 0.4029 - val_accuracy: 0.8363\n",
      "Epoch 5/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.3186 - accuracy: 0.8684 - val_loss: 0.4342 - val_accuracy: 0.8284\n",
      "Epoch 6/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.3313 - accuracy: 0.8553 - val_loss: 0.3837 - val_accuracy: 0.8402\n",
      "Epoch 7/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.3043 - accuracy: 0.8724 - val_loss: 0.3707 - val_accuracy: 0.8402\n",
      "Epoch 8/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2876 - accuracy: 0.8763 - val_loss: 0.3772 - val_accuracy: 0.8501\n",
      "Epoch 9/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2448 - accuracy: 0.9026 - val_loss: 0.3854 - val_accuracy: 0.8402\n",
      "Epoch 10/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2660 - accuracy: 0.8855 - val_loss: 0.4314 - val_accuracy: 0.8343\n",
      "Epoch 11/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2482 - accuracy: 0.8974 - val_loss: 0.3616 - val_accuracy: 0.8501\n",
      "Epoch 12/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2194 - accuracy: 0.8961 - val_loss: 0.3472 - val_accuracy: 0.8619\n",
      "Epoch 13/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.2121 - accuracy: 0.9132 - val_loss: 0.3886 - val_accuracy: 0.8481\n",
      "Epoch 14/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1947 - accuracy: 0.9211 - val_loss: 0.3842 - val_accuracy: 0.8442\n",
      "Epoch 15/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1832 - accuracy: 0.9250 - val_loss: 0.3688 - val_accuracy: 0.8659\n",
      "Epoch 16/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1737 - accuracy: 0.9303 - val_loss: 0.3841 - val_accuracy: 0.8580\n",
      "Epoch 17/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1670 - accuracy: 0.9316 - val_loss: 0.3776 - val_accuracy: 0.8422\n",
      "Epoch 18/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1755 - accuracy: 0.9289 - val_loss: 0.3392 - val_accuracy: 0.8718\n",
      "Epoch 19/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1551 - accuracy: 0.9474 - val_loss: 0.3581 - val_accuracy: 0.8619\n",
      "Epoch 20/20\n",
      "760/760 [==============================] - 2s 3ms/step - loss: 0.1336 - accuracy: 0.9553 - val_loss: 0.3664 - val_accuracy: 0.8540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a37a11fd0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(data, np.array(y_train), validation_split=0.4, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           10000000  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,080,501\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 10,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6589487 ],\n",
       "       [0.23531099]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tweet = ['stock market up big enjoy','equal pay']\n",
    "seq1 = tokenizer.texts_to_sequences(new_tweet)\n",
    "da1 = pad_sequences(seq1, maxlen=50)\n",
    "pred1 = mod.predict(da1)\n",
    "#labels=['Republican','Democrat']\n",
    "#print(pred1, labels[np.argmax(pred1)])\n",
    "pred1\n",
    "# 0: Democrat, 1: Republican"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
